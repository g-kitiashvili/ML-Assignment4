{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u_g7VSgeCtz"
      },
      "source": [
        "# Experiment 07: Tiny CNN - Underfitting Analysis\n",
        "## Objective: Demonstrate underfitting with an intentionally small model and analyze capacity limitations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D_YUJ_WeCvM"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install wandb -q\n",
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IKYDsm3eCvO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy2zIfSreCvS"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional - for saving results)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnxxB68qeCvT"
      },
      "outputs": [],
      "source": [
        "# Setup kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3od-1b4CeCvU"
      },
      "outputs": [],
      "source": [
        "# Download FER2013 dataset from Kaggle\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "# Extract the dataset\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7BQOua1eCvX"
      },
      "outputs": [],
      "source": [
        "# Initialize W&B\n",
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project=\"fer-challenge\",\n",
        "    name=\"exp07-tiny-cnn-underfitting\",\n",
        "    config={\n",
        "        \"architecture\": \"Tiny CNN (Underfitting)\",\n",
        "        \"dataset\": \"FER2013\",\n",
        "        \"epochs\": 50,  # More epochs to see if tiny model can learn\n",
        "        \"batch_size\": 64,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"weight_decay\": 0.0,  # No regularization\n",
        "        \"dropout\": 0.0,  # No dropout\n",
        "        \"batch_norm\": False,  # No batch norm\n",
        "        \"conv_blocks\": 2,  # Very few blocks\n",
        "        \"conv_channels\": [16, 32],  # Very small channels\n",
        "        \"fc_sizes\": [64],  # Very small FC layer\n",
        "        \"num_classes\": 7,\n",
        "        \"model_purpose\": \"demonstrate_underfitting\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5fte5SleCvZ"
      },
      "outputs": [],
      "source": [
        "# Load and explore the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
        "print(\"\\nEmotion distribution:\")\n",
        "print(train_df['emotion'].value_counts().sort_index())\n",
        "\n",
        "icml_df = pd.read_csv('icml_face_data.csv')\n",
        "\n",
        "# Split ICML data based on 'Usage'\n",
        "icml_train = icml_df[icml_df[' Usage'] == 'Training']\n",
        "icml_test = icml_df[icml_df[' Usage'].isin(['PublicTest', 'Other'])]\n",
        "\n",
        "# Drop the 'Usage' column (not needed after splitting)\n",
        "icml_train = icml_train.drop(columns=[' Usage'])\n",
        "icml_test = icml_test.drop(columns=[' Usage'])\n",
        "\n",
        "# Merge datasets\n",
        "train_df = pd.concat([train_df, icml_train], ignore_index=True)\n",
        "test_df = pd.concat([test_df, icml_test], ignore_index=True)\n",
        "\n",
        "# **Added data type check and filtering**\n",
        "print(\"\\nChecking 'pixels' column data types...\")\n",
        "initial_train_rows = len(train_df)\n",
        "initial_test_rows = len(test_df)\n",
        "\n",
        "train_df = train_df[train_df['pixels'].apply(lambda x: isinstance(x, str))]\n",
        "test_df = test_df[test_df['pixels'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "print(f\"Removed {initial_train_rows - len(train_df)} rows from training set due to non-string 'pixels'.\")\n",
        "print(f\"Removed {initial_test_rows - len(test_df)} rows from test set due to non-string 'pixels'.\")\n",
        "\n",
        "# Shuffle the merged datasets (optional but recommended)\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Output shapes and emotion distribution\n",
        "print(\"\\nMerged Train shape (after filtering):\", train_df.shape)\n",
        "print(\"Merged Test shape (after filtering):\", test_df.shape)\n",
        "\n",
        "print(\"\\nEmotion distribution in merged train set:\")\n",
        "print(train_df['emotion'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEmotion distribution in merged test set:\")\n",
        "print(test_df['emotion'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TinOcncIeCva"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(8):\n",
        "    idx = np.random.randint(0, len(train_df))\n",
        "    pixels = train_df.iloc[idx]['pixels']\n",
        "    emotion = train_df.iloc[idx]['emotion']\n",
        "\n",
        "    # Convert pixel string to array and reshape\n",
        "    pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.uint8)\n",
        "    pixels = pixels.reshape(48, 48)\n",
        "\n",
        "    axes[i].imshow(pixels, cmap='gray')\n",
        "    axes[i].set_title(f'{emotion_labels[emotion]}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Sample Images from FER2013 Dataset')\n",
        "plt.tight_layout()\n",
        "wandb.log({\"sample_images\": wandb.Image(plt)})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2JAUa9ReCvb"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        emotion = self.data.iloc[idx]['emotion']\n",
        "\n",
        "        # Convert pixel string to numpy array\n",
        "        pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.float32)\n",
        "        pixels = pixels / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        # For CNN, reshape to (1, 48, 48) - single channel\n",
        "        pixels = pixels.reshape(1, 48, 48)\n",
        "\n",
        "        return torch.tensor(pixels), torch.tensor(emotion, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bflabsmOeCvc"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "full_dataset = FERDataset(train_df)\n",
        "\n",
        "# Split into train and validation\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqz9tzV0eCvc"
      },
      "outputs": [],
      "source": [
        "# Tiny CNN Model - Intentionally Too Small\n",
        "class TinyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(TinyCNN, self).__init__()\n",
        "\n",
        "        # Only 2 convolutional blocks with very few filters\n",
        "        # Block 1: Very small number of filters\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)  # Large kernel, few filters\n",
        "        self.pool1 = nn.MaxPool2d(4, 4)  # Aggressive pooling\n",
        "\n",
        "        # Block 2: Still very small\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(4, 4)  # More aggressive pooling\n",
        "\n",
        "        # Very small fully connected layer\n",
        "        # After two 4x4 poolings: 48/4/4 = 3x3\n",
        "        self.fc1 = nn.Linear(32 * 3 * 3, 64)  # Very small hidden layer\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "        # Simple activation\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Calculate total parameters\n",
        "        self.total_params = sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv Block 1\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Conv Block 2\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # FC layers\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-viGxgTeeCve"
      },
      "outputs": [],
      "source": [
        "# Initialize model, loss, optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = TinyCNN().to(device)\n",
        "print(f\"Total parameters: {model.total_params:,}\")\n",
        "print(f\"Model size comparison:\")\n",
        "print(f\"  - Tiny CNN: {model.total_params:,} parameters\")\n",
        "print(f\"  - Typical CNN: ~500K-2M parameters\")\n",
        "print(f\"  - Large CNN: ~10M+ parameters\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# No weight decay - we want to see pure underfitting\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Log model architecture to W&B\n",
        "wandb.watch(model, log='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYZ3bHDWeCve"
      },
      "outputs": [],
      "source": [
        "# Print model architecture\n",
        "print(\"Tiny Model Architecture:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Convolutional Layers:\")\n",
        "print(\"  Conv1: 1 -> 16 filters (5x5 kernel)\")\n",
        "print(\"  Pool1: 4x4 pooling (aggressive)\")\n",
        "print(\"  Conv2: 16 -> 32 filters (5x5 kernel)\")\n",
        "print(\"  Pool2: 4x4 pooling (aggressive)\")\n",
        "print(\"\\nFully Connected Layers:\")\n",
        "print(\"  FC1: 288 -> 64 (very small hidden layer)\")\n",
        "print(\"  FC2: 64 -> 7\")\n",
        "print(\"\\nTotal Layers: 4 (2 conv + 2 fc)\")\n",
        "print(f\"Total Parameters: {model.total_params:,}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Compare with typical model sizes\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name:15} {param.shape} -> {param.numel():,} params\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jji8FLFIeCve"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(loader, desc='Training')\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': loss.item(),\n",
        "            'acc': 100 * correct / total\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InYKU51eeCvf"
      },
      "outputs": [],
      "source": [
        "# Validation function\n",
        "def validate_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(loader, desc='Validation')\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'acc': 100 * correct / total\n",
        "            })\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_predictions, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN9Ok8bVeCvg"
      },
      "outputs": [],
      "source": [
        "# Training loop - Extended to see if tiny model can eventually learn\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "best_val_acc = 0\n",
        "\n",
        "# Train for more epochs to see the underfitting behavior\n",
        "num_epochs = 50\n",
        "\n",
        "print(\"Starting training of intentionally tiny model...\")\n",
        "print(\"Expected behavior: Both training and validation accuracy should plateau at low values\")\n",
        "print(\"This demonstrates underfitting due to insufficient model capacity.\\n\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "    print('-' * 50)\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc, predictions, labels = validate_epoch(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # Log to W&B\n",
        "    wandb.log({\n",
        "        'epoch': epoch + 1,\n",
        "        'train_loss': train_loss,\n",
        "        'train_acc': train_acc,\n",
        "        'val_loss': val_loss,\n",
        "        'val_acc': val_acc,\n",
        "        'learning_rate': optimizer.param_groups[0]['lr'],\n",
        "        'overfitting_gap': train_acc - val_acc,\n",
        "        'underfitting_indicator': max(train_acc, val_acc) < 40  # Low accuracy indicates underfitting\n",
        "    })\n",
        "\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print(f'Gap: {train_acc - val_acc:.2f}% (small gap indicates underfitting)')\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_tiny_cnn_model.pth')\n",
        "        print(f'New best model saved with validation accuracy: {val_acc:.2f}%')\n",
        "        \n",
        "    # Check for underfitting signs\n",
        "    if epoch > 10:\n",
        "        recent_train_acc = np.mean(train_accs[-5:])\n",
        "        recent_val_acc = np.mean(val_accs[-5:])\n",
        "        if recent_train_acc < 40 and recent_val_acc < 40:\n",
        "            print(\"UNDERFITTING DETECTED: Both training and validation accuracy are low\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfQfsN2aeCvg"
      },
      "outputs": [],
      "source": [
        "# Plot training history emphasizing underfitting patterns\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(train_losses, label='Train Loss', linewidth=2, color='blue')\n",
        "ax1.plot(val_losses, label='Val Loss', linewidth=2, color='orange')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss\\n(Notice both remain high - underfitting)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot with reference lines\n",
        "ax2.plot(train_accs, label='Train Acc', linewidth=2, color='blue')\n",
        "ax2.plot(val_accs, label='Val Acc', linewidth=2, color='orange')\n",
        "ax2.axhline(y=100/7, color='red', linestyle='--', alpha=0.7, label='Random Guess (14.3%)')\n",
        "ax2.axhline(y=50, color='green', linestyle='--', alpha=0.7, label='Reasonable Performance (50%)')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy\\n(Both plateau at low values - underfitting)')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim(0, 60)\n",
        "\n",
        "plt.tight_layout()\n",
        "wandb.log({\"underfitting_analysis\": wandb.Image(plt)})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "underfitting_analysis"
      },
      "outputs": [],
      "source": [
        "# Detailed underfitting analysis\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"UNDERFITTING ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Calculate key metrics\n",
        "final_train_acc = train_accs[-1]\n",
        "final_val_acc = val_accs[-1]\n",
        "max_train_acc = max(train_accs)\n",
        "max_val_acc = max(val_accs)\n",
        "overfitting_gaps = [train_accs[i] - val_accs[i] for i in range(len(train_accs))]\n",
        "avg_gap = np.mean(overfitting_gaps)\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  - Final Training Accuracy: {final_train_acc:.2f}%\")\n",
        "print(f\"  - Final Validation Accuracy: {final_val_acc:.2f}%\")\n",
        "print(f\"  - Maximum Training Accuracy: {max_train_acc:.2f}%\")\n",
        "print(f\"  - Maximum Validation Accuracy: {max_val_acc:.2f}%\")\n",
        "print(f\"  - Average Train-Val Gap: {avg_gap:.2f}%\")\n",
        "\n",
        "print(f\"\\nUnderfitting Indicators:\")\n",
        "print(f\"  - Low absolute performance: {max_val_acc < 40}\")\n",
        "print(f\"  - Small train-val gap: {abs(avg_gap) < 5}\")\n",
        "print(f\"  - Training accuracy plateau: {max_train_acc - train_accs[10] < 5 if len(train_accs) > 10 else 'N/A'}\")\n",
        "\n",
        "# Compare with random baseline\n",
        "random_accuracy = 100 / 7  # 7 classes\n",
        "print(f\"\\nBaseline Comparison:\")\n",
        "print(f\"  - Random Guess Accuracy: {random_accuracy:.2f}%\")\n",
        "print(f\"  - Model vs Random: +{max_val_acc - random_accuracy:.2f} percentage points\")\n",
        "print(f\"  - Improvement over random: {(max_val_acc / random_accuracy - 1) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hncz0I7aeCvg"
      },
      "outputs": [],
      "source": [
        "# Plot learning curves with underfitting indicators\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create subplot for detailed analysis\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(train_accs, 'b-', linewidth=2, label='Training')\n",
        "plt.plot(val_accs, 'r-', linewidth=2, label='Validation')\n",
        "plt.axhline(y=random_accuracy, color='gray', linestyle='--', alpha=0.7, label='Random')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Learning Curves - Underfitting Pattern')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(overfitting_gaps, 'g-', linewidth=2)\n",
        "plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train - Val Accuracy (%)')\n",
        "plt.title('Overfitting Gap (Small = Underfitting)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(train_losses, 'b-', linewidth=2, label='Training')\n",
        "plt.plot(val_losses, 'r-', linewidth=2, label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curves - Both Remain High')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Show model capacity vs problem complexity\n",
        "model_capacity = model.total_params\n",
        "problem_complexity = len(train_df)  # Dataset size as proxy\n",
        "capacity_ratio = model_capacity / problem_complexity * 1000  # Scale for visualization\n",
        "\n",
        "plt.bar(['Model\\nCapacity', 'Problem\\nComplexity\\n(scaled)'], \n",
        "        [model_capacity, problem_complexity/1000], \n",
        "        color=['red', 'blue'], alpha=0.7)\n",
        "plt.ylabel('Count')\n",
        "plt.title('Model Capacity vs Problem Complexity')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "wandb.log({\"underfitting_detailed_analysis\": wandb.Image(plt)})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZwcaaoHeCvh"
      },
      "outputs": [],
      "source": [
        "# Load best model for final evaluation\n",
        "model.load_state_dict(torch.load('best_tiny_cnn_model.pth'))\n",
        "_, _, final_predictions, final_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(final_labels, final_predictions)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=emotion_labels,\n",
        "            yticklabels=emotion_labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Tiny CNN (Underfitting)\\nNote: Poor performance across all classes')\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "plt.show()\n",
        "\n",
        "# Analyze confusion matrix for underfitting signs\n",
        "print(\"\\nConfusion Matrix Analysis:\")\n",
        "print(f\"  - Diagonal sum (correct predictions): {np.trace(cm)}\")\n",
        "print(f\"  - Total predictions: {np.sum(cm)}\")\n",
        "print(f\"  - Accuracy from CM: {np.trace(cm)/np.sum(cm)*100:.2f}%\")\n",
        "\n",
        "# Check if model is biased towards certain classes\n",
        "predicted_class_counts = np.sum(cm, axis=0)\n",
        "actual_class_counts = np.sum(cm, axis=1)\n",
        "print(f\"\\nClass Prediction Analysis:\")\n",
        "for i, emotion in enumerate(emotion_labels):\n",
        "    print(f\"  {emotion}: Predicted {predicted_class_counts[i]}, Actual {actual_class_counts[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbmHpH5YeCvh"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"=\" * 70)\n",
        "report = classification_report(final_labels, final_predictions,\n",
        "                             target_names=emotion_labels,\n",
        "                             output_dict=True)\n",
        "print(classification_report(final_labels, final_predictions, target_names=emotion_labels))\n",
        "\n",
        "# Log per-class metrics to W&B\n",
        "for emotion in emotion_labels:\n",
        "    wandb.log({\n",
        "        f\"{emotion}_precision\": report[emotion]['precision'],\n",
        "        f\"{emotion}_recall\": report[emotion]['recall'],\n",
        "        f\"{emotion}_f1\": report[emotion]['f1-score']\n",
        "    })\n",
        "\n",
        "# Analyze per-class performance for underfitting\n",
        "print(\"\\nPer-class Performance Analysis:\")\n",
        "for emotion in emotion_labels:\n",
        "    f1 = report[emotion]['f1-score']\n",
        "    if f1 < 0.3:\n",
        "        print(f\"  - {emotion}: Very poor performance (F1={f1:.3f}) - indicates underfitting\")\n",
        "    elif f1 < 0.5:\n",
        "        print(f\"  - {emotion}: Poor performance (F1={f1:.3f}) - likely underfitting\")\n",
        "    else:\n",
        "        print(f\"  - {emotion}: Reasonable performance (F1={f1:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMlv8C-XeCvh"
      },
      "outputs": [],
      "source": [
        "# Model capacity analysis\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MODEL CAPACITY ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Calculate theoretical model capacity\n",
        "input_size = 48 * 48  # Input image size\n",
        "num_classes = 7\n",
        "dataset_size = len(train_df)\n",
        "\n",
        "print(f\"\\nProblem Characteristics:\")\n",
        "print(f\"  - Input Dimensions: {input_size:,} pixels\")\n",
        "print(f\"  - Number of Classes: {num_classes}\")\n",
        "print(f\"  - Training Samples: {dataset_size:,}\")\n",
        "print(f\"  - Complexity Estimate: High (facial expressions)\")\n",
        "\n",
        "print(f\"\\nModel Characteristics:\")\n",
        "print(f\"  - Total Parameters: {model.total_params:,}\")\n",
        "print(f\"  - Parameters per Input Pixel: {model.total_params/input_size:.3f}\")\n",
        "print(f\"  - Parameters per Training Sample: {model.total_params/dataset_size:.3f}\")\n",
        "print(f\"  - Bottleneck Layer Size: 64 neurons\")\n",
        "\n",
        "# Rule of thumb comparisons\n",
        "print(f\"\\nCapacity Assessment:\")\n",
        "params_per_sample = model.total_params / dataset_size\n",
        "if params_per_sample < 0.1:\n",
        "    print(f\"  - SEVERELY UNDERCAPACITATED: {params_per_sample:.3f} params/sample\")\n",
        "elif params_per_sample < 1:\n",
        "    print(f\"  - UNDERCAPACITATED: {params_per_sample:.3f} params/sample\")\n",
        "else:\n",
        "    print(f\"  - Adequate capacity: {params_per_sample:.3f} params/sample\")\n",
        "\n",
        "print(f\"\\nRecommendations to Fix Underfitting:\")\n",
        "print(f\"  1. Increase model size (more filters, layers)\")\n",
        "print(f\"  2. Reduce aggressive pooling\")\n",
        "print(f\"  3. Add more convolutional layers\")\n",
        "print(f\"  4. Increase fully connected layer sizes\")\n",
        "print(f\"  5. Remove regularization (if any)\")\n",
        "print(f\"  6. Train for more epochs\")\n",
        "print(f\"  7. Try different architectures (ResNet, etc.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QEvKNzieCvh"
      },
      "outputs": [],
      "source": [
        "# Save final model and log to W&B\n",
        "torch.save(model.state_dict(), 'final_tiny_cnn_model.pth')\n",
        "wandb.save('final_tiny_cnn_model.pth')\n",
        "wandb.save('best_tiny_cnn_model.pth')\n",
        "\n",
        "# Summary statistics emphasizing underfitting\n",
        "summary_stats = {\n",
        "    \"final_train_accuracy\": train_accs[-1],\n",
        "    \"final_val_accuracy\": val_accs[-1],\n",
        "    \"best_val_accuracy\": best_val_acc,\n",
        "    \"max_train_accuracy\": max(train_accs),\n",
        "    \"overfitting_gap\": train_accs[-1] - val_accs[-1],\n",
        "    \"avg_overfitting_gap\": np.mean(overfitting_gaps),\n",
        "    \"total_parameters\": model.total_params,\n",
        "    \"macro_f1_score\": report['macro avg']['f1-score'],\n",
        "    \"weighted_f1_score\": report['weighted avg']['f1-score'],\n",
        "    \"improvement_over_random\": best_val_acc - random_accuracy,\n",
        "    \"underfitting_confirmed\": best_val_acc < 40,\n",
        "    \"parameters_per_sample\": model.total_params / len(train_df),\n",
        "    \"training_epochs\": len(train_losses)\n",
        "}\n",
        "\n",
        "wandb.log(summary_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR3_7g-QeCvi"
      },
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXPERIMENT SUMMARY: TINY CNN - UNDERFITTING DEMONSTRATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(f\"  - Intentionally Small Design\")\n",
        "print(f\"  - 2 Convolutional Layers (16, 32 filters)\")\n",
        "print(f\"  - Aggressive Pooling (4x4)\")\n",
        "print(f\"  - Small FC layer (64 neurons)\")\n",
        "print(f\"  - Total Parameters: {model.total_params:,}\")\n",
        "print(f\"  - No Regularization Applied\")\n",
        "\n",
        "print(f\"\\nUnderfitting Evidence:\")\n",
        "print(f\"  - Final Training Accuracy: {train_accs[-1]:.2f}%\")\n",
        "print(f\"  - Final Validation Accuracy: {val_accs[-1]:.2f}%\")\n",
        "print(f\"  - Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"  - Small Train-Val Gap: {np.mean(overfitting_gaps):.2f}%\")\n",
        "print(f\"  - Low Absolute Performance: {best_val_acc < 40}\")\n",
        "print(f\"  - Improvement over Random: +{best_val_acc - random_accuracy:.2f}pp\")\n",
        "print(f\"  - Macro F1-Score: {report['macro avg']['f1-score']:.3f}\")\n",
        "\n",
        "print(f\"\\nKey Insights:\")\n",
        "print(f\"  - Model lacks sufficient capacity for the task\")\n",
        "print(f\"  - Both training and validation accuracy plateau at low values\")\n",
        "print(f\"  - Minimal overfitting due to insufficient model complexity\")\n",
        "print(f\"  - Poor performance across all emotion classes\")\n",
        "print(f\"  - Training for more epochs doesn't help\")\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
