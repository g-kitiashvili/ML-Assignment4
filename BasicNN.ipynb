{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 01: Basic Neural Network Baseline\n",
    "## Objective: Demonstrate why CNNs are better than fully connected networks for image data\n",
    "\n",
    "This experiment uses a simple fully connected neural network to establish a baseline for the FER2013 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install wandb -q\n",
    "!pip install kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - for saving results)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle API\n",
    "# You need to upload your kaggle.json file when prompted\n",
    "from google.colab import files\n",
    "\n",
    "# Upload kaggle.json\n",
    "print(\"Please upload your kaggle.json file\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Setup kaggle directory\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download FER2013 dataset from Kaggle\n",
    "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "\n",
    "# Extract the dataset\n",
    "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    project=\"fer-challenge\",\n",
    "    name=\"exp01-basic-nn\",\n",
    "    config={\n",
    "        \"architecture\": \"Basic NN\",\n",
    "        \"dataset\": \"FER2013\",\n",
    "        \"epochs\": 30,\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"hidden_size1\": 512,\n",
    "        \"hidden_size2\": 256,\n",
    "        \"hidden_size3\": 128,\n",
    "        \"input_size\": 48*48,\n",
    "        \"num_classes\": 7\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
    "print(\"\\nEmotion distribution:\")\n",
    "print(train_df['emotion'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    idx = np.random.randint(0, len(train_df))\n",
    "    pixels = train_df.iloc[idx]['pixels']\n",
    "    emotion = train_df.iloc[idx]['emotion']\n",
    "    \n",
    "    # Convert pixel string to array and reshape\n",
    "    pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.uint8)\n",
    "    pixels = pixels.reshape(48, 48)\n",
    "    \n",
    "    axes[i].imshow(pixels, cmap='gray')\n",
    "    axes[i].set_title(f'{emotion_labels[emotion]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from FER2013 Dataset')\n",
    "plt.tight_layout()\n",
    "wandb.log({\"sample_images\": wandb.Image(plt)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pixels = self.data.iloc[idx]['pixels']\n",
    "        emotion = self.data.iloc[idx]['emotion']\n",
    "        \n",
    "        # Convert pixel string to numpy array\n",
    "        pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.float32)\n",
    "        pixels = pixels / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        # For basic NN, we keep it as a flat vector\n",
    "        # For CNN experiments, we'll reshape to (1, 48, 48)\n",
    "        \n",
    "        return torch.tensor(pixels), torch.tensor(emotion, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "full_dataset = FERDataset(train_df)\n",
    "\n",
    "# Split into train and validation\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Neural Network Model\n",
    "class BasicNN(nn.Module):\n",
    "    def __init__(self, input_size=48*48, hidden_size1=512, hidden_size2=256, hidden_size3=128, num_classes=7):\n",
    "        super(BasicNN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_size3, num_classes)\n",
    "        \n",
    "        # Calculate total parameters\n",
    "        self.total_params = sum(p.numel() for p in self.parameters())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = BasicNN().to(device)\n",
    "print(f\"Total parameters: {model.total_params:,}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Log model architecture to W&B\n",
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "print(\"Model Architecture:\")\n",
    "print(\"=\" * 50)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:20} {param.shape}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc='Training')\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'acc': 100 * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(loader, desc='Validation')\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'acc': 100 * correct / total\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(f'\\nEpoch {epoch+1}/30')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, predictions, labels = validate_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr']\n",
    "    })\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_basic_nn_model.pth')\n",
    "        print(f'New best model saved with validation accuracy: {val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "ax1.plot(val_losses, label='Val Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accs, label='Train Acc', linewidth=2)\n",
    "ax2.plot(val_accs, label='Val Acc', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "wandb.log({\"training_history\": wandb.Image(plt)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for final evaluation\n",
    "model.load_state_dict(torch.load('best_basic_nn_model.pth'))\n",
    "_, _, final_predictions, final_labels = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(final_labels, final_predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotion_labels, \n",
    "            yticklabels=emotion_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Basic NN')\n",
    "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 70)\n",
    "report = classification_report(final_labels, final_predictions, \n",
    "                             target_names=emotion_labels, \n",
    "                             output_dict=True)\n",
    "print(classification_report(final_labels, final_predictions, target_names=emotion_labels))\n",
    "\n",
    "# Log per-class metrics to W&B\n",
    "for emotion in emotion_labels:\n",
    "    wandb.log({\n",
    "        f\"{emotion}_precision\": report[emotion]['precision'],\n",
    "        f\"{emotion}_recall\": report[emotion]['recall'],\n",
    "        f\"{emotion}_f1\": report[emotion]['f1-score']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassifications\n",
    "misclassified_indices = np.where(np.array(final_predictions) != np.array(final_labels))[0]\n",
    "correct_indices = np.where(np.array(final_predictions) == np.array(final_labels))[0]\n",
    "\n",
    "print(f\"\\nTotal misclassifications: {len(misclassified_indices)} out of {len(final_labels)}\")\n",
    "print(f\"Misclassification rate: {len(misclassified_indices)/len(final_labels)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model and log to W&B\n",
    "torch.save(model.state_dict(), 'final_basic_nn_model.pth')\n",
    "wandb.save('final_basic_nn_model.pth')\n",
    "wandb.save('best_basic_nn_model.pth')\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = {\n",
    "    \"final_train_accuracy\": train_accs[-1],\n",
    "    \"final_val_accuracy\": val_accs[-1],\n",
    "    \"best_val_accuracy\": best_val_acc,\n",
    "    \"overfitting_gap\": train_accs[-1] - val_accs[-1],\n",
    "    \"total_parameters\": model.total_params,\n",
    "    \"macro_f1_score\": report['macro avg']['f1-score'],\n",
    "    \"weighted_f1_score\": report['weighted avg']['f1-score']\n",
    "}\n",
    "\n",
    "wandb.log(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT SUMMARY: BASIC NEURAL NETWORK\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  - Input Layer: 2,304 neurons (48x48 pixels)\")\n",
    "print(f\"  - Hidden Layer 1: 512 neurons\")\n",
    "print(f\"  - Hidden Layer 2: 256 neurons\")\n",
    "print(f\"  - Hidden Layer 3: 128 neurons\")\n",
    "print(f\"  - Output Layer: 7 neurons (emotions)\")\n",
    "print(f\"  - Total Parameters: {model.total_params:,}\")\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  - Final Training Accuracy: {train_accs[-1]:.2f}%\")\n",
    "print(f\"  - Final Validation Accuracy: {val_accs[-1]:.2f}%\")\n",
    "print(f\"  - Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"  - Overfitting Gap: {train_accs[-1] - val_accs[-1]:.2f}%\")\n",
    "print(f\"  - Macro F1-Score: {report['macro avg']['f1-score']:.3f}\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"  1. Basic NN treats the image as a flat vector, losing spatial structure\")\n",
    "print(\"  2. Performance is significantly limited compared to expected CNN performance\")\n",
    "print(\"  3. The model shows signs of overfitting despite relatively low accuracy\")\n",
    "print(\"  4. High parameter count (1.28M) for the achieved performance\")\n",
    "print(\"  5. Certain emotions (Happy, Surprise) are easier to classify than others\")\n",
    "\n",
    "print(\"\\nConclusions:\")\n",
    "print(\"  - Spatial information is crucial for facial expression recognition\")\n",
    "print(\"  - Convolutional layers should significantly improve performance\")\n",
    "print(\"  - Need for better feature extraction mechanisms\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Close W&B run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
