{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 01: Basic Neural Network (Fully Connected)\n",
    "\n",
    "**Objective**: Establish baseline using a basic neural network without convolutions.\n",
    "\n",
    "**Hypothesis**: A fully connected network will perform poorly on image data because it doesn't capture spatial relationships.\n",
    "\n",
    "**Expected Result**: Low accuracy (~25-30%) due to treating pixels independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision wandb pandas numpy matplotlib seaborn scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Available Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files we have\n",
    "print(\"Available CSV files:\")\n",
    "for file in os.listdir('.'):\n",
    "    if file.endswith('.csv'):\n",
    "        print(f\"  - {file}\")\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"    Shape: {df.shape}, Columns: {df.columns.tolist()[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FER2013Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file: 'train.csv' or 'test.csv'\n",
    "            transform: transformations to apply\n",
    "            is_test: True if using test.csv (no labels)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        print(f\"Loaded {csv_file}: {len(self.data)} samples\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get pixels - check column name\n",
    "        if 'pixels' in self.data.columns:\n",
    "            pixels = self.data.iloc[idx]['pixels']\n",
    "        else:\n",
    "            # If pixels are in separate columns (pixel0, pixel1, ...)\n",
    "            pixel_cols = [col for col in self.data.columns if col.startswith('pixel')]\n",
    "            if pixel_cols:\n",
    "                pixels = ' '.join([str(self.data.iloc[idx][col]) for col in pixel_cols])\n",
    "            else:\n",
    "                raise ValueError(\"Cannot find pixel data in CSV\")\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        pixels = np.array([int(p) for p in pixels.split()], dtype=np.uint8)\n",
    "        pixels = pixels.reshape(48, 48)\n",
    "        \n",
    "        # Convert to 3-channel\n",
    "        pixels = np.stack([pixels] * 3, axis=-1)\n",
    "        \n",
    "        # Get label\n",
    "        if self.is_test:\n",
    "            label = 0  # Dummy label for test set\n",
    "        else:\n",
    "            if 'emotion' in self.data.columns:\n",
    "                label = int(self.data.iloc[idx]['emotion'])\n",
    "            elif 'label' in self.data.columns:\n",
    "                label = int(self.data.iloc[idx]['label'])\n",
    "            else:\n",
    "                raise ValueError(\"Cannot find label column\")\n",
    "        \n",
    "        if self.transform:\n",
    "            pixels = self.transform(pixels)\n",
    "            \n",
    "        return pixels, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Basic Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(BasicNN, self).__init__()\n",
    "        # Flatten image: 48*48*3 = 6912\n",
    "        self.fc1 = nn.Linear(48 * 48 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten - loses spatial structure!\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load full training data\n",
    "if os.path.exists('train.csv'):\n",
    "    full_train_dataset = FER2013Dataset('train.csv', transform=transform)\n",
    "    \n",
    "    # Split into train/val (80/20)\n",
    "    train_size = int(0.8 * len(full_train_dataset))\n",
    "    val_size = len(full_train_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_train_dataset, [train_size, val_size]\n",
    "    )\n",
    "    print(f\"Train: {train_size}, Val: {val_size}\")\n",
    "    \n",
    "    # Test dataset\n",
    "    if os.path.exists('test.csv'):\n",
    "        test_dataset = FER2013Dataset('test.csv', transform=transform, is_test=True)\n",
    "    else:\n",
    "        test_dataset = None\n",
    "        print(\"No test.csv found\")\n",
    "else:\n",
    "    # Fallback to icml_face_data.csv if train.csv doesn't exist\n",
    "    print(\"Using icml_face_data.csv instead\")\n",
    "    from torch.utils.data import Subset\n",
    "    \n",
    "    class ICML_Dataset(Dataset):\n",
    "        def __init__(self, csv_file='icml_face_data.csv', usage='Training', transform=None):\n",
    "            data = pd.read_csv(csv_file)\n",
    "            self.data = data[data['Usage'] == usage].reset_index(drop=True)\n",
    "            self.transform = transform\n",
    "            print(f\"{usage}: {len(self.data)} samples\")\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            pixels = self.data.iloc[idx]['pixels']\n",
    "            pixels = np.array([int(p) for p in pixels.split()], dtype=np.uint8).reshape(48, 48)\n",
    "            pixels = np.stack([pixels] * 3, axis=-1)\n",
    "            label = int(self.data.iloc[idx]['emotion'])\n",
    "            \n",
    "            if self.transform:\n",
    "                pixels = self.transform(pixels)\n",
    "            return pixels, label\n",
    "    \n",
    "    train_dataset = ICML_Dataset(usage='Training', transform=transform)\n",
    "    val_dataset = ICML_Dataset(usage='PublicTest', transform=transform)\n",
    "    test_dataset = ICML_Dataset(usage='PrivateTest', transform=transform)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) if test_dataset else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb.init(\n",
    "    project=\"fer-challenge\",\n",
    "    name=\"01_BasicNN\",\n",
    "    config={\n",
    "        \"model\": \"BasicNN\",\n",
    "        \"epochs\": 30,\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"architecture\": \"4 FC layers\",\n",
    "        \"expected\": \"Poor performance due to no spatial feature extraction\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using: {device}\")\n",
    "\n",
    "model = BasicNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"\\nExpected: Low accuracy (~25-30%) because:\")\n",
    "print(\"- Treats each pixel independently\")\n",
    "print(\"- No spatial feature extraction\")\n",
    "print(\"- Loses all 2D structure when flattening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(f\"\\nEpoch {epoch+1}/30\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Overfitting Gap: {train_acc - val_acc:.2f}%\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"overfitting_gap\": train_acc - val_acc,\n",
    "        \"epoch\": epoch\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(train_losses, label='Train', linewidth=2)\n",
    "ax1.plot(val_losses, label='Val', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training vs Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(train_accs, label='Train', linewidth=2)\n",
    "ax2.plot(val_accs, label='Val', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training vs Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "wandb.log({\"training_curves\": wandb.Image(plt)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: Basic Neural Network (Fully Connected)\")\n",
    "print(f\"Best Validation Accuracy: {max(val_accs):.2f}%\")\n",
    "print(f\"Final Training Accuracy: {train_accs[-1]:.2f}%\")\n",
    "print(f\"Final Overfitting Gap: {train_accs[-1] - val_accs[-1]:.2f}%\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"1. Poor performance: {max(val_accs):.2f}% (random guessing = 14.3%)\")\n",
    "print(\"2. The model struggles because it treats pixels independently\")\n",
    "print(\"3. No spatial feature extraction capability\")\n",
    "print(\"4. This demonstrates why CNNs are necessary for image tasks\")\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"Basic NNs are inadequate for image classification.\")\n",
    "print(\"We need convolutional layers to capture spatial patterns!\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
