{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN Experiment\n",
    "\n",
    "Simple CNN to establish baseline performance on FER2013 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision wandb pandas numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive for kaggle.json\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
    "\n",
    "# Extract tar.gz if present\n",
    "if os.path.exists('fer2013.tar.gz'):\n",
    "    !tar -xzf fer2013.tar.gz\n",
    "    print(\"Extracted fer2013.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files we have\n",
    "print(\"Available CSV files:\")\n",
    "!ls -la *.csv\n",
    "\n",
    "# Check the structure of each file\n",
    "for file in ['train.csv', 'test.csv', 'icml_face_data.csv']:\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"\\n{file}: {df.shape}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        print(f\"First row sample: {df.iloc[0].values[:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Handles both train.csv and test.csv formats\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        print(f\"Loaded {csv_file} with shape: {self.data.shape}\")\n",
    "        print(f\"Columns: {self.data.columns.tolist()[:5]}...\")  # Show first 5 columns\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Get emotion label (first column in train.csv)\n",
    "        if self.is_test:\n",
    "            label = 0  # No labels in test set\n",
    "        else:\n",
    "            label = int(row[0])  # First column is emotion\n",
    "        \n",
    "        # Get pixels (second column in train.csv, first in test.csv)\n",
    "        if self.is_test:\n",
    "            pixels = row[0]  # First column in test.csv\n",
    "        else:\n",
    "            pixels = row[1]  # Second column in train.csv\n",
    "            \n",
    "        # Convert pixels string to numpy array\n",
    "        pixels = np.array(pixels.split(' '), dtype='float32').reshape(48, 48)\n",
    "        pixels = pixels / 255.0  # normalize to [0, 1]\n",
    "        \n",
    "        # Convert to 3 channel image\n",
    "        image = np.stack([pixels] * 3, axis=2)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n",
    "        self.fc2 = nn.Linear(256, 7)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1, 128 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Use train.csv for training\n",
    "if os.path.exists('train.csv'):\n",
    "    print(\"Using train.csv for training\")\n",
    "    train_dataset = FERDataset('train.csv', transform=transform, is_test=False)\n",
    "    \n",
    "    # Split into train/val (80/20)\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    print(f\"Train: {train_size}, Val: {val_size}\")\n",
    "else:\n",
    "    print(\"train.csv not found!\")\n",
    "\n",
    "# Create loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"fer-challenge\", name=\"basic-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_acc = 100. * train_correct / len(train_dataset)\n",
    "    val_acc = 100. * val_correct / len(val_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"train_loss\": train_loss/len(train_loader),\n",
    "        \"val_loss\": val_loss/len(val_loader)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
