{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u_g7VSgeCtz"
      },
      "source": [
        "# Experiment 06: Very Deep CNN\n",
        "## Objective: Explore the impact of network depth on performance and training dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D_YUJ_WeCvM"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install wandb -q\n",
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IKYDsm3eCvO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy2zIfSreCvS"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional - for saving results)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnxxB68qeCvT"
      },
      "outputs": [],
      "source": [
        "# Setup kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3od-1b4CeCvU"
      },
      "outputs": [],
      "source": [
        "# Download FER2013 dataset from Kaggle\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "# Extract the dataset\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7BQOua1eCvX"
      },
      "outputs": [],
      "source": [
        "# Initialize W&B\n",
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project=\"fer-challenge\",\n",
        "    name=\"exp06-very-deep-cnn\",\n",
        "    config={\n",
        "        \"architecture\": \"Very Deep CNN (VGG-19 style)\",\n",
        "        \"dataset\": \"FER2013\",\n",
        "        \"epochs\": 30,\n",
        "        \"batch_size\": 32,  # Smaller batch size for deeper model\n",
        "        \"learning_rate\": 0.0001,  # Lower learning rate for stability\n",
        "        \"weight_decay\": 0.0001,\n",
        "        \"dropout_conv\": 0.2,\n",
        "        \"dropout_fc\": 0.5,\n",
        "        \"batch_norm\": True,\n",
        "        \"conv_blocks\": 6,\n",
        "        \"conv_channels\": [64, 128, 256, 512, 512, 512],\n",
        "        \"fc_sizes\": [4096, 2048, 1024],\n",
        "        \"num_classes\": 7\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5fte5SleCvZ"
      },
      "outputs": [],
      "source": [
        "# Load and explore the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
        "print(\"\\nEmotion distribution:\")\n",
        "print(train_df['emotion'].value_counts().sort_index())\n",
        "\n",
        "icml_df = pd.read_csv('icml_face_data.csv')\n",
        "\n",
        "# Split ICML data based on 'Usage'\n",
        "icml_train = icml_df[icml_df[' Usage'] == 'Training']\n",
        "icml_test = icml_df[icml_df[' Usage'].isin(['PublicTest', 'Other'])]\n",
        "\n",
        "# Drop the 'Usage' column (not needed after splitting)\n",
        "icml_train = icml_train.drop(columns=[' Usage'])\n",
        "icml_test = icml_test.drop(columns=[' Usage'])\n",
        "\n",
        "# Merge datasets\n",
        "train_df = pd.concat([train_df, icml_train], ignore_index=True)\n",
        "test_df = pd.concat([test_df, icml_test], ignore_index=True)\n",
        "\n",
        "# **Added data type check and filtering**\n",
        "print(\"\\nChecking 'pixels' column data types...\")\n",
        "initial_train_rows = len(train_df)\n",
        "initial_test_rows = len(test_df)\n",
        "\n",
        "train_df = train_df[train_df['pixels'].apply(lambda x: isinstance(x, str))]\n",
        "test_df = test_df[test_df['pixels'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "print(f\"Removed {initial_train_rows - len(train_df)} rows from training set due to non-string 'pixels'.\")\n",
        "print(f\"Removed {initial_test_rows - len(test_df)} rows from test set due to non-string 'pixels'.\")\n",
        "\n",
        "# Shuffle the merged datasets (optional but recommended)\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Output shapes and emotion distribution\n",
        "print(\"\\nMerged Train shape (after filtering):\", train_df.shape)\n",
        "print(\"Merged Test shape (after filtering):\", test_df.shape)\n",
        "\n",
        "print(\"\\nEmotion distribution in merged train set:\")\n",
        "print(train_df['emotion'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEmotion distribution in merged test set:\")\n",
        "print(test_df['emotion'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TinOcncIeCva"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(8):\n",
        "    idx = np.random.randint(0, len(train_df))\n",
        "    pixels = train_df.iloc[idx]['pixels']\n",
        "    emotion = train_df.iloc[idx]['emotion']\n",
        "\n",
        "    # Convert pixel string to array and reshape\n",
        "    pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.uint8)\n",
        "    pixels = pixels.reshape(48, 48)\n",
        "\n",
        "    axes[i].imshow(pixels, cmap='gray')\n",
        "    axes[i].set_title(f'{emotion_labels[emotion]}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Sample Images from FER2013 Dataset')\n",
        "plt.tight_layout()\n",
        "wandb.log({\"sample_images\": wandb.Image(plt)})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2JAUa9ReCvb"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        emotion = self.data.iloc[idx]['emotion']\n",
        "\n",
        "        # Convert pixel string to numpy array\n",
        "        pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.float32)\n",
        "        pixels = pixels / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        # For CNN, reshape to (1, 48, 48) - single channel\n",
        "        pixels = pixels.reshape(1, 48, 48)\n",
        "\n",
        "        return torch.tensor(pixels), torch.tensor(emotion, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bflabsmOeCvc"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "full_dataset = FERDataset(train_df)\n",
        "\n",
        "# Split into train and validation\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "\n",
        "# Create data loaders with smaller batch size for deeper model\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqz9tzV0eCvc"
      },
      "outputs": [],
      "source": [
        "# Very Deep CNN Model (VGG-19 inspired)\n",
        "class VeryDeepCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout_conv=0.2, dropout_fc=0.5):\n",
        "        super(VeryDeepCNN, self).__init__()\n",
        "\n",
        "        # Block 1: 64 channels\n",
        "        self.conv1_1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(64)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout2d(dropout_conv)\n",
        "\n",
        "        # Block 2: 128 channels\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(128)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout2 = nn.Dropout2d(dropout_conv)\n",
        "\n",
        "        # Block 3: 256 channels\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(256)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn3_3 = nn.BatchNorm2d(256)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn3_4 = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout3 = nn.Dropout2d(dropout_conv)\n",
        "\n",
        "        # Block 4: 512 channels\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(512)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(512)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn4_3 = nn.BatchNorm2d(512)\n",
        "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn4_4 = nn.BatchNorm2d(512)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout4 = nn.Dropout2d(dropout_conv)\n",
        "\n",
        "        # Block 5: 512 channels (deeper)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(512)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5_2 = nn.BatchNorm2d(512)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5_3 = nn.BatchNorm2d(512)\n",
        "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5_4 = nn.BatchNorm2d(512)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout5 = nn.Dropout2d(dropout_conv)\n",
        "\n",
        "        # Block 6: 512 channels (even deeper)\n",
        "        self.conv6_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn6_1 = nn.BatchNorm2d(512)\n",
        "        self.conv6_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn6_2 = nn.BatchNorm2d(512)\n",
        "        self.dropout6 = nn.Dropout2d(dropout_conv)\n",
        "\n",
        "        # Adaptive pooling to handle any input size\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers (very large)\n",
        "        self.fc1 = nn.Linear(512, 4096)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(4096)\n",
        "        self.dropout_fc1 = nn.Dropout(dropout_fc)\n",
        "\n",
        "        self.fc2 = nn.Linear(4096, 2048)\n",
        "        self.bn_fc2 = nn.BatchNorm1d(2048)\n",
        "        self.dropout_fc2 = nn.Dropout(dropout_fc)\n",
        "\n",
        "        self.fc3 = nn.Linear(2048, 1024)\n",
        "        self.bn_fc3 = nn.BatchNorm1d(1024)\n",
        "        self.dropout_fc3 = nn.Dropout(dropout_fc)\n",
        "\n",
        "        self.fc4 = nn.Linear(1024, num_classes)\n",
        "\n",
        "        # Activation\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Calculate total parameters\n",
        "        self.total_params = sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = self.relu(self.bn1_2(self.conv1_2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = self.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = self.relu(self.bn2_2(self.conv2_2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = self.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = self.relu(self.bn3_2(self.conv3_2(x)))\n",
        "        x = self.relu(self.bn3_3(self.conv3_3(x)))\n",
        "        x = self.relu(self.bn3_4(self.conv3_4(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        # Block 4\n",
        "        x = self.relu(self.bn4_1(self.conv4_1(x)))\n",
        "        x = self.relu(self.bn4_2(self.conv4_2(x)))\n",
        "        x = self.relu(self.bn4_3(self.conv4_3(x)))\n",
        "        x = self.relu(self.bn4_4(self.conv4_4(x)))\n",
        "        x = self.pool4(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        # Block 5\n",
        "        x = self.relu(self.bn5_1(self.conv5_1(x)))\n",
        "        x = self.relu(self.bn5_2(self.conv5_2(x)))\n",
        "        x = self.relu(self.bn5_3(self.conv5_3(x)))\n",
        "        x = self.relu(self.bn5_4(self.conv5_4(x)))\n",
        "        x = self.pool5(x)\n",
        "        x = self.dropout5(x)\n",
        "\n",
        "        # Block 6\n",
        "        x = self.relu(self.bn6_1(self.conv6_1(x)))\n",
        "        x = self.relu(self.bn6_2(self.conv6_2(x)))\n",
        "        x = self.dropout6(x)\n",
        "\n",
        "        # Adaptive pooling and flatten\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # FC layers\n",
        "        x = self.relu(self.bn_fc1(self.fc1(x)))\n",
        "        x = self.dropout_fc1(x)\n",
        "\n",
        "        x = self.relu(self.bn_fc2(self.fc2(x)))\n",
        "        x = self.dropout_fc2(x)\n",
        "\n",
        "        x = self.relu(self.bn_fc3(self.fc3(x)))\n",
        "        x = self.dropout_fc3(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-viGxgTeeCve"
      },
      "outputs": [],
      "source": [
        "# Initialize model, loss, optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = VeryDeepCNN().to(device)\n",
        "print(f\"Total parameters: {model.total_params:,}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Lower learning rate for deeper model stability\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
        "\n",
        "# Learning rate scheduler for deep networks\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "# Log model architecture to W&B\n",
        "wandb.watch(model, log='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYZ3bHDWeCve"
      },
      "outputs": [],
      "source": [
        "# Print model architecture summary\n",
        "print(\"Model Architecture Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Convolutional Blocks:\")\n",
        "print(\"  Block 1: 1 -> 64 -> 64 (2 conv layers)\")\n",
        "print(\"  Block 2: 64 -> 128 -> 128 (2 conv layers)\")\n",
        "print(\"  Block 3: 128 -> 256 -> 256 -> 256 -> 256 (4 conv layers)\")\n",
        "print(\"  Block 4: 256 -> 512 -> 512 -> 512 -> 512 (4 conv layers)\")\n",
        "print(\"  Block 5: 512 -> 512 -> 512 -> 512 -> 512 (4 conv layers)\")\n",
        "print(\"  Block 6: 512 -> 512 -> 512 (2 conv layers)\")\n",
        "print(\"\\nTotal Convolutional Layers: 18\")\n",
        "print(\"\\nFully Connected Layers:\")\n",
        "print(\"  FC1: 512 -> 4096\")\n",
        "print(\"  FC2: 4096 -> 2048\")\n",
        "print(\"  FC3: 2048 -> 1024\")\n",
        "print(\"  FC4: 1024 -> 7\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jji8FLFIeCve"
      },
      "outputs": [],
      "source": [
        "# Training function with gradient clipping for deep networks\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    grad_norms = []\n",
        "\n",
        "    progress_bar = tqdm(loader, desc='Training')\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping for stability in deep networks\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        grad_norms.append(grad_norm.item())\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': loss.item(),\n",
        "            'acc': 100 * correct / total,\n",
        "            'grad_norm': grad_norm.item()\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    avg_grad_norm = np.mean(grad_norms)\n",
        "\n",
        "    return epoch_loss, epoch_acc, avg_grad_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InYKU51eeCvf"
      },
      "outputs": [],
      "source": [
        "# Validation function\n",
        "def validate_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(loader, desc='Validation')\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'acc': 100 * correct / total\n",
        "            })\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_predictions, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN9Ok8bVeCvg"
      },
      "outputs": [],
      "source": [
        "# Training loop with additional monitoring for deep networks\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "grad_norms = []\n",
        "best_val_acc = 0\n",
        "patience_counter = 0\n",
        "early_stopping_patience = 10\n",
        "\n",
        "for epoch in range(30):\n",
        "    print(f'\\nEpoch {epoch+1}/30')\n",
        "    print('-' * 50)\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc, avg_grad_norm = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    grad_norms.append(avg_grad_norm)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc, predictions, labels = validate_epoch(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    # Step scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Log to W&B\n",
        "    wandb.log({\n",
        "        'epoch': epoch + 1,\n",
        "        'train_loss': train_loss,\n",
        "        'train_acc': train_acc,\n",
        "        'val_loss': val_loss,\n",
        "        'val_acc': val_acc,\n",
        "        'learning_rate': optimizer.param_groups[0]['lr'],\n",
        "        'overfitting_gap': train_acc - val_acc,\n",
        "        'gradient_norm': avg_grad_norm\n",
        "    })\n",
        "\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print(f'Overfitting Gap: {train_acc - val_acc:.2f}%')\n",
        "    print(f'Average Gradient Norm: {avg_grad_norm:.4f}')\n",
        "    print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_very_deep_cnn_model.pth')\n",
        "        print(f'New best model saved with validation accuracy: {val_acc:.2f}%')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        \n",
        "    # Early stopping for very deep networks\n",
        "    if patience_counter >= early_stopping_patience:\n",
        "        print(f'Early stopping triggered after {epoch+1} epochs')\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfQfsN2aeCvg"
      },
      "outputs": [],
      "source": [
        "# Plot training history with gradient norms\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
        "ax1.plot(val_losses, label='Val Loss', linewidth=2)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(train_accs, label='Train Acc', linewidth=2)\n",
        "ax2.plot(val_accs, label='Val Acc', linewidth=2)\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Gradient norm plot\n",
        "ax3.plot(grad_norms, 'g-', linewidth=2)\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Gradient Norm')\n",
        "ax3.set_title('Average Gradient Norm During Training')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Overfitting gap plot\n",
        "overfitting_gaps = [train_accs[i] - val_accs[i] for i in range(len(train_accs))]\n",
        "ax4.plot(overfitting_gaps, 'r-', linewidth=2)\n",
        "ax4.set_xlabel('Epoch')\n",
        "ax4.set_ylabel('Overfitting Gap (%)')\n",
        "ax4.set_title('Overfitting Gap Throughout Training')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "wandb.log({\"training_history\": wandb.Image(plt)})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZwcaaoHeCvh"
      },
      "outputs": [],
      "source": [
        "# Load best model for final evaluation\n",
        "model.load_state_dict(torch.load('best_very_deep_cnn_model.pth'))\n",
        "_, _, final_predictions, final_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(final_labels, final_predictions)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=emotion_labels,\n",
        "            yticklabels=emotion_labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Very Deep CNN')\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbmHpH5YeCvh"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"=\" * 70)\n",
        "report = classification_report(final_labels, final_predictions,\n",
        "                             target_names=emotion_labels,\n",
        "                             output_dict=True)\n",
        "print(classification_report(final_labels, final_predictions, target_names=emotion_labels))\n",
        "\n",
        "# Log per-class metrics to W&B\n",
        "for emotion in emotion_labels:\n",
        "    wandb.log({\n",
        "        f\"{emotion}_precision\": report[emotion]['precision'],\n",
        "        f\"{emotion}_recall\": report[emotion]['recall'],\n",
        "        f\"{emotion}_f1\": report[emotion]['f1-score']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMlv8C-XeCvh"
      },
      "outputs": [],
      "source": [
        "# Analyze training dynamics for deep networks\n",
        "print(f\"\\nTraining Dynamics Analysis:\")\n",
        "print(f\"  - Initial Gradient Norm: {grad_norms[0]:.4f}\")\n",
        "print(f\"  - Final Gradient Norm: {grad_norms[-1]:.4f}\")\n",
        "print(f\"  - Max Gradient Norm: {max(grad_norms):.4f}\")\n",
        "print(f\"  - Min Gradient Norm: {min(grad_norms):.4f}\")\n",
        "print(f\"  - Average Gradient Norm: {np.mean(grad_norms):.4f}\")\n",
        "\n",
        "misclassified_indices = np.where(np.array(final_predictions) != np.array(final_labels))[0]\n",
        "print(f\"\\nTotal misclassifications: {len(misclassified_indices)} out of {len(final_labels)}\")\n",
        "print(f\"Misclassification rate: {len(misclassified_indices)/len(final_labels)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QEvKNzieCvh"
      },
      "outputs": [],
      "source": [
        "# Save final model and log to W&B\n",
        "torch.save(model.state_dict(), 'final_very_deep_cnn_model.pth')\n",
        "wandb.save('final_very_deep_cnn_model.pth')\n",
        "wandb.save('best_very_deep_cnn_model.pth')\n",
        "\n",
        "# Summary statistics\n",
        "summary_stats = {\n",
        "    \"final_train_accuracy\": train_accs[-1],\n",
        "    \"final_val_accuracy\": val_accs[-1],\n",
        "    \"best_val_accuracy\": best_val_acc,\n",
        "    \"overfitting_gap\": train_accs[-1] - val_accs[-1],\n",
        "    \"max_overfitting_gap\": max(overfitting_gaps),\n",
        "    \"total_parameters\": model.total_params,\n",
        "    \"macro_f1_score\": report['macro avg']['f1-score'],\n",
        "    \"weighted_f1_score\": report['weighted avg']['f1-score'],\n",
        "    \"avg_gradient_norm\": np.mean(grad_norms),\n",
        "    \"training_epochs\": len(train_losses)\n",
        "}\n",
        "\n",
        "wandb.log(summary_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR3_7g-QeCvi"
      },
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXPERIMENT SUMMARY: VERY DEEP CNN\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(f\"  - 6 Convolutional Blocks (VGG-19 style)\")\n",
        "print(f\"  - Total Conv Layers: 18\")\n",
        "print(f\"  - Conv channels: [64, 128, 256, 512, 512, 512]\")\n",
        "print(f\"  - FC layers: [4096, 2048, 1024, 7]\")\n",
        "print(f\"  - Total Parameters: {model.total_params:,}\")\n",
        "print(f\"  - Gradient Clipping: max_norm=1.0\")\n",
        "print(f\"  - Learning Rate Scheduling: ReduceLROnPlateau\")\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  - Final Training Accuracy: {train_accs[-1]:.2f}%\")\n",
        "print(f\"  - Final Validation Accuracy: {val_accs[-1]:.2f}%\")\n",
        "print(f\"  - Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "        print(f\"  - Final Overfitting Gap: {train_accs[-1] - val_accs[-1]:.2f}%\")\n",
        "print(f\"  - Maximum Overfitting Gap: {max(overfitting_gaps):.2f}%\")\n",
        "print(f\"  - Macro F1-Score: {report['macro avg']['f1-score']:.3f}\")\n",
        "print(f\"  - Training Epochs: {len(train_losses)}\")\n",
        "print(f\"  - Average Gradient Norm: {np.mean(grad_norms):.4f}\")\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
