{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u_g7VSgeCtz"
      },
      "source": [
        "# Experiment 09: Optimizer Comparison\n",
        "## Objective: Compare SGD, Adam, and RMSprop optimizers on facial expression recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D_YUJ_WeCvM"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install wandb -q\n",
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IKYDsm3eCvO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "import copy\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy2zIfSreCvS"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional - for saving results)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnxxB68qeCvT"
      },
      "outputs": [],
      "source": [
        "# Setup kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3od-1b4CeCvU"
      },
      "outputs": [],
      "source": [
        "# Download FER2013 dataset from Kaggle\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "# Extract the dataset\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5fte5SleCvZ"
      },
      "outputs": [],
      "source": [
        "# Load and explore the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
        "print(\"\\nEmotion distribution:\")\n",
        "print(train_df['emotion'].value_counts().sort_index())\n",
        "\n",
        "icml_df = pd.read_csv('icml_face_data.csv')\n",
        "\n",
        "# Split ICML data based on 'Usage'\n",
        "icml_train = icml_df[icml_df[' Usage'] == 'Training']\n",
        "icml_test = icml_df[icml_df[' Usage'].isin(['PublicTest', 'Other'])]\n",
        "\n",
        "# Drop the 'Usage' column (not needed after splitting)\n",
        "icml_train = icml_train.drop(columns=[' Usage'])\n",
        "icml_test = icml_test.drop(columns=[' Usage'])\n",
        "\n",
        "# Merge datasets\n",
        "train_df = pd.concat([train_df, icml_train], ignore_index=True)\n",
        "test_df = pd.concat([test_df, icml_test], ignore_index=True)\n",
        "\n",
        "# **Added data type check and filtering**\n",
        "print(\"\\nChecking 'pixels' column data types...\")\n",
        "initial_train_rows = len(train_df)\n",
        "initial_test_rows = len(test_df)\n",
        "\n",
        "train_df = train_df[train_df['pixels'].apply(lambda x: isinstance(x, str))]\n",
        "test_df = test_df[test_df['pixels'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "print(f\"Removed {initial_train_rows - len(train_df)} rows from training set due to non-string 'pixels'.\")\n",
        "print(f\"Removed {initial_test_rows - len(test_df)} rows from test set due to non-string 'pixels'.\")\n",
        "\n",
        "# Shuffle the merged datasets (optional but recommended)\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Output shapes and emotion distribution\n",
        "print(\"\\nMerged Train shape (after filtering):\", train_df.shape)\n",
        "print(\"Merged Test shape (after filtering):\", test_df.shape)\n",
        "\n",
        "print(\"\\nEmotion distribution in merged train set:\")\n",
        "print(train_df['emotion'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEmotion distribution in merged test set:\")\n",
        "print(test_df['emotion'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TinOcncIeCva"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(8):\n",
        "    idx = np.random.randint(0, len(train_df))\n",
        "    pixels = train_df.iloc[idx]['pixels']\n",
        "    emotion = train_df.iloc[idx]['emotion']\n",
        "\n",
        "    # Convert pixel string to array and reshape\n",
        "    pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.uint8)\n",
        "    pixels = pixels.reshape(48, 48)\n",
        "\n",
        "    axes[i].imshow(pixels, cmap='gray')\n",
        "    axes[i].set_title(f'{emotion_labels[emotion]}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Sample Images from FER2013 Dataset')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2JAUa9ReCvb"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        emotion = self.data.iloc[idx]['emotion']\n",
        "\n",
        "        # Convert pixel string to numpy array\n",
        "        pixels = np.array([int(pixel) for pixel in pixels.split(' ')], dtype=np.float32)\n",
        "        pixels = pixels / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        # For CNN, reshape to (1, 48, 48) - single channel\n",
        "        pixels = pixels.reshape(1, 48, 48)\n",
        "\n",
        "        return torch.tensor(pixels), torch.tensor(emotion, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bflabsmOeCvc"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "full_dataset = FERDataset(train_df)\n",
        "\n",
        "# Split into train and validation\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqz9tzV0eCvc"
      },
      "outputs": [],
      "source": [
        "# CNN Model for Optimizer Comparison\n",
        "class OptimizerTestCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(OptimizerTestCNN, self).__init__()\n",
        "\n",
        "        # Conv Block 1\n",
        "        self.conv1_1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Conv Block 2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Conv Block 3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Activation and dropout\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # Calculate total parameters\n",
        "        self.total_params = sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv Block 1\n",
        "        x = self.relu(self.conv1_1(x))\n",
        "        x = self.relu(self.conv1_2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Conv Block 2\n",
        "        x = self.relu(self.conv2_1(x))\n",
        "        x = self.relu(self.conv2_2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Conv Block 3\n",
        "        x = self.relu(self.conv3_1(x))\n",
        "        x = self.relu(self.conv3_2(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # FC layers\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-viGxgTeeCve"
      },
      "outputs": [],
      "source": [
        "# Initialize device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create a sample model to check parameter count\n",
        "sample_model = OptimizerTestCNN().to(device)\n",
        "print(f\"Total parameters: {sample_model.total_params:,}\")\n",
        "del sample_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYZ3bHDWeCve"
      },
      "outputs": [],
      "source": [
        "# Define optimizer configurations\n",
        "optimizer_configs = {\n",
        "    'SGD': {\n",
        "        'optimizer_class': optim.SGD,\n",
        "        'params': {'lr': 0.01, 'momentum': 0.9, 'weight_decay': 1e-4},\n",
        "        'scheduler': True,\n",
        "        'color': 'red'\n",
        "    },\n",
        "    'Adam': {\n",
        "        'optimizer_class': optim.Adam,\n",
        "        'params': {'lr': 0.001, 'weight_decay': 1e-4},\n",
        "        'scheduler': False,\n",
        "        'color': 'blue'\n",
        "    },\n",
        "    'RMSprop': {\n",
        "        'optimizer_class': optim.RMSprop,\n",
        "        'params': {'lr': 0.001, 'weight_decay': 1e-4, 'momentum': 0.9},\n",
        "        'scheduler': False,\n",
        "        'color': 'green'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Optimizer Configurations:\")\n",
        "print(\"=\" * 50)\n",
        "for name, config in optimizer_configs.items():\n",
        "    print(f\"{name}: {config['params']}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jji8FLFIeCve"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InYKU51eeCvf"
      },
      "outputs": [],
      "source": [
        "# Validation function\n",
        "def validate_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_predictions, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN9Ok8bVeCvg"
      },
      "outputs": [],
      "source": [
        "# Train models with different optimizers\n",
        "results = {}\n",
        "num_epochs = 25\n",
        "\n",
        "for optimizer_name, config in optimizer_configs.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training with {optimizer_name} optimizer\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Initialize W&B run for this optimizer\n",
        "    wandb.init(\n",
        "        project=\"fer-challenge\",\n",
        "        name=f\"exp09-optimizer-{optimizer_name.lower()}\",\n",
        "        config={\n",
        "            \"architecture\": \"CNN for Optimizer Comparison\",\n",
        "            \"dataset\": \"FER2013\",\n",
        "            \"epochs\": num_epochs,\n",
        "            \"batch_size\": 64,\n",
        "            \"optimizer\": optimizer_name,\n",
        "            **config['params'],\n",
        "            \"num_classes\": 7\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Initialize model\n",
        "    model = OptimizerTestCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Initialize optimizer\n",
        "    optimizer = config['optimizer_class'](model.parameters(), **config['params'])\n",
        "    \n",
        "    # Initialize scheduler for SGD\n",
        "    scheduler = None\n",
        "    if config['scheduler']:\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    \n",
        "    # Track metrics\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    learning_rates = []\n",
        "    best_val_acc = 0\n",
        "    \n",
        "    # Log model to W&B\n",
        "    wandb.watch(model, log='all')\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs} - {optimizer_name}')\n",
        "        print('-' * 40)\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, predictions, labels = validate_epoch(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        # Get current learning rate\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        learning_rates.append(current_lr)\n",
        "\n",
        "        # Step scheduler if applicable\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Log to W&B\n",
        "        wandb.log({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "            'learning_rate': current_lr,\n",
        "            'overfitting_gap': train_acc - val_acc\n",
        "        })\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "        print(f'Learning Rate: {current_lr:.6f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'best_{optimizer_name.lower()}_model.pth')\n",
        "    \n",
        "    # Store results\n",
        "    results[optimizer_name] = {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accs': val_accs,\n",
        "        'learning_rates': learning_rates,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'final_train_acc': train_accs[-1],\n",
        "        'final_val_acc': val_accs[-1],\n",
        "        'model': model,\n",
        "        'color': config['color']\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{optimizer_name} - Best Val Acc: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Finish W&B run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfQfsN2aeCvg"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of all optimizers\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "# Training Loss\n",
        "for optimizer_name, data in results.items():\n",
        "    axes[0, 0].plot(data['train_losses'], label=optimizer_name, \n",
        "                   color=data['color'], linewidth=2)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Training Loss')\n",
        "axes[0, 0].set_title('Training Loss Comparison')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Loss\n",
        "for optimizer_name, data in results.items():\n",
        "    axes[0, 1].plot(data['val_losses'], label=optimizer_name, \n",
        "                   color=data['color'], linewidth=2)\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Validation Loss')\n",
        "axes[0, 1].set_title('Validation Loss Comparison')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Training Accuracy\n",
        "for optimizer_name, data in results.items():\n",
        "    axes[1, 0].plot(data['train_accs'], label=optimizer_name, \n",
        "                   color=data['color'], linewidth=2)\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Training Accuracy (%)')\n",
        "axes[1, 0].set_title('Training Accuracy Comparison')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Accuracy\n",
        "for optimizer_name, data in results.items():\n",
        "    axes[1, 1].plot(data['val_accs'], label=optimizer_name, \n",
        "                   color=data['color'], linewidth=2)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Validation Accuracy (%)')\n",
        "axes[1, 1].set_title('Validation Accuracy Comparison')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning Rate Schedule\n",
        "for optimizer_name, data in results.items():\n",
        "    axes[0, 2].plot(data['learning_rates'], label=optimizer_name, \n",
        "                   color=data
        "                   ['color'], linewidth=2)\n"
        "axes[0, 2].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Validation Accuracy (%)')\n",
        "axes[1, 1].set_title('Validation Accuracy Comparison')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning Rate Schedule\n",
        "for optimizer_name, data in results.items():\n",
        "    axes[0, 2].plot(data['learning_rates'], label=optimizer_name, \n",
        "                   color=data['color'], linewidth=2)\n",
        "axes[0, 2].set_xlabel('Epoch')\n",
        "axes[0, 2].set_ylabel('Learning Rate')\n",
        "axes[0, 2].set_title('Learning Rate Schedule')\n",
        "axes[0, 2].legend()\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "axes[0, 2].set_yscale('log')\n",
        "\n",
        "# Overfitting Gap\n",
        "for optimizer_name, data in results.items():\n",
        "    overfitting_gaps = [data['train_accs'][i] - data['val_accs'][i] for i in range(len(data['train_accs']))]\n",
        "    axes[1, 2].plot(overfitting_gaps, label=optimizer_name, \n",
        "                   color=data['color'], linewidth=2)\n",
        "axes[1, 2].set_xlabel('Epoch')\n",
        "axes[1, 2].set_ylabel('Overfitting Gap (%)')\n",
        "axes[1, 2].set_title('Overfitting Gap Comparison')\n",
        "axes[1, 2].legend()\n",
        "axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hncz0I7aeCvg"
      },
      "outputs": [],
      "source": [
        "# Create convergence speed comparison\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot validation accuracy with different line styles\n",
        "line_styles = ['-', '--', '-.']\n",
        "for i, (optimizer_name, data) in enumerate(results.items()):\n",
        "    plt.plot(data['val_accs'], label=f'{optimizer_name} (Best: {data[\"best_val_acc\"]:.2f}%)', \n",
        "             color=data['color'], linewidth=3, linestyle=line_styles[i])\n",
        "\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Validation Accuracy (%)', fontsize=12)\n",
        "plt.title('Optimizer Convergence Speed Comparison', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(0, num_epochs-1)\n",
        "\n",
        "# Add annotations for best performance\n",
        "for optimizer_name, data in results.items():\n",
        "    best_epoch = np.argmax(data['val_accs'])\n",
        "    plt.annotate(f'{data[\"best_val_acc\"]:.1f}%', \n",
        "                xy=(best_epoch, data['best_val_acc']), \n",
        "                xytext=(10, 10), textcoords='offset points',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor=data['color'], alpha=0.3),\n",
        "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZwcaaoHeCvh"
      },
      "outputs": [],
      "source": [
        "# Performance summary table\n",
        "summary_data = []\n",
        "for optimizer_name, data in results.items():\n",
        "    summary_data.append({\n",
        "        'Optimizer': optimizer_name,\n",
        "        'Best Val Acc (%)': f\"{data['best_val_acc']:.2f}\",\n",
        "        'Final Train Acc (%)': f\"{data['final_train_acc']:.2f}\",\n",
        "        'Final Val Acc (%)': f\"{data['final_val_acc']:.2f}\",\n",
        "        'Final Overfitting Gap (%)': f\"{data['final_train_acc'] - data['final_val_acc']:.2f}\",\n",
        "        'Epochs to Best': np.argmax(data['val_accs']) + 1,\n",
        "        'Final Train Loss': f\"{data['train_losses'][-1]:.4f}\",\n",
        "        'Final Val Loss': f\"{data['val_losses'][-1]:.4f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\nOptimizer Performance Summary:\")\n",
        "print(\"=\" * 120)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\" * 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbmHpH5YeCvh"
      },
      "outputs": [],
      "source": [
        "# Find the best performing optimizer\n",
        "best_optimizer = max(results.keys(), key=lambda x: results[x]['best_val_acc'])\n",
        "best_model = results[best_optimizer]['model']\n",
        "\n",
        "print(f\"\\nBest performing optimizer: {best_optimizer}\")\n",
        "print(f\"Best validation accuracy: {results[best_optimizer]['best_val_acc']:.2f}%\")\n",
        "\n",
        "# Load the best model and evaluate\n",
        "best_model.load_state_dict(torch.load(f'best_{best_optimizer.lower()}_model.pth'))\n",
        "_, _, final_predictions, final_labels = validate_epoch(best_model, val_loader, nn.CrossEntropyLoss(), device)\n",
        "\n",
        "# Confusion matrix for best model\n",
        "cm = confusion_matrix(final_labels, final_predictions)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=emotion_labels,\n",
        "            yticklabels=emotion_labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'Confusion Matrix - Best Model ({best_optimizer})')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMlv8C-XeCvh"
      },
      "outputs": [],
      "source": [
        "# Classification report for best model\n",
        "print(f\"\\nClassification Report - Best Model ({best_optimizer}):\")\n",
        "print(\"=\" * 70)\n",
        "report = classification_report(final_labels, final_predictions,\n",
        "                             target_names=emotion_labels,\n",
        "                             output_dict=True)\n",
        "print(classification_report(final_labels, final_predictions, target_names=emotion_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QEvKNzieCvh"
      },
      "outputs": [],
      "source": [
        "# Analyze convergence characteristics\n",
        "print(\"\\nConvergence Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for optimizer_name, data in results.items():\n",
        "    # Find when 90% of best performance was reached\n",
        "    target_acc = 0.9 * data['best_val_acc']\n",
        "    convergence_epoch = next((i for i, acc in enumerate(data['val_accs']) if acc >= target_acc), num_epochs)\n",
        "    \n",
        "    # Calculate stability (std dev of last 5 epochs)\n",
        "    stability = np.std(data['val_accs'][-5:])\n",
        "    \n",
        "    # Calculate average improvement per epoch in first 10 epochs\n",
        "    early_improvement = (data['val_accs'][9] - data['val_accs'][0]) / 10\n",
        "    \n",
        "    print(f\"{optimizer_name}:\")\n",
        "    print(f\"  - Convergence Speed (90% of best): Epoch {convergence_epoch + 1}\")\n",
        "    print(f\"  - Stability (last 5 epochs std): {stability:.3f}\")\n",
        "    print(f\"  - Early Improvement Rate: {early_improvement:.3f}% per epoch\")\n",
        "    print(f\"  - Final Learning Rate: {data['learning_rates'][-1]:.6f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR3_7g-QeCvi"
      },
      "outputs": [],
      "source": [
        "# Create detailed loss landscape comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, (optimizer_name, data) in enumerate(results.items()):\n",
        "    epochs = range(1, len(data['train_losses']) + 1)\n",
        "    \n",
        "    axes[i].plot(epochs, data['train_losses'], 'o-', label='Train Loss', \n",
        "                color=data['color'], alpha=0.7, linewidth=2)\n",
        "    axes[i].plot(epochs, data['val_losses'], 's-', label='Val Loss', \n",
        "                color=data['color'], alpha=0.9, linewidth=2)\n",
        "    \n",
        "    axes[i].set_xlabel('Epoch')\n",
        "    axes[i].set_ylabel('Loss')\n",
        "    axes[i].set_title(f'{optimizer_name} Loss Progression')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add best validation point\n",
        "    best_epoch = np.argmin(data['val_losses'])\n",
        "    axes[i].scatter(best_epoch + 1, data['val_losses'][best_epoch], \n",
        "                   color='red', s=100, zorder=5, marker='*')\n",
        "    axes[i].annotate(f'Best: {data[\"val_losses\"][best_epoch]:.3f}', \n",
        "                    xy=(best_epoch + 1, data['val_losses'][best_epoch]),\n",
        "                    xytext=(10, 10), textcoords='offset points',\n",
        "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.3))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbmHpH5YeCvi"
      },
      "outputs": [],
      "source": [
        "# Save all models and create final summary\n",
        "for optimizer_name in results.keys():\n",
        "    torch.save(results[optimizer_name]['model'].state_dict(), \n",
        "               f'final_{optimizer_name.lower()}_model.pth')\n",
        "\n",
        "# Initialize final W&B run for comparison\n",
        "wandb.init(\n",
        "    project=\"fer-challenge\",\n",
        "    name=\"exp09-optimizer-comparison-summary\",\n",
        "    config={\n",
        "        \"experiment\": \"Optimizer Comparison\",\n",
        "        \"optimizers\": list(optimizer_configs.keys()),\n",
        "        \"dataset\": \"FER2013\",\n",
        "        \"epochs\": num_epochs,\n",
        "        \"architecture\": \"CNN for Optimizer Comparison\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Log comparison metrics\n",
        "comparison_metrics = {}\n",
        "for optimizer_name, data in results.items():\n",
        "    comparison_metrics.update({\n",
        "        f\"{optimizer_name}_best_val_acc\": data['best_val_acc'],\n",
        "        f\"{optimizer_name}_final_train_acc\": data['final_train_acc'],\n",
        "        f\"{optimizer_name}_final_val_acc\": data['final_val_acc'],\n",
        "        f\"{optimizer_name}_overfitting_gap\": data['final_train_acc'] - data['final_val_acc'],\n",
        "        f\"{optimizer_name}_epochs_to_best\": np.argmax(data['val_accs']) + 1\n",
        "    })\n",
        "\n",
        "wandb.log(comparison_metrics)\n",
        "\n",
        "# Save models to W&B\n",
        "for optimizer_name in results.keys():\n",
        "    wandb.save(f'final_{optimizer_name.lower()}_model.pth')\n",
        "    wandb.save(f'best_{optimizer_name.lower()}_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN9Ok8bVeCvi"
      },
      "outputs": [],
      "source": [
        "# Final comprehensive analysis\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT SUMMARY: OPTIMIZER COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(f\"  - 3 Convolutional Blocks\")\n",
        "print(f\"  - Conv channels: [64, 128, 256]\")\n",
        "print(f\"  - FC layers: [512, 256, 7]\")\n",
        "print(f\"  - Total Parameters: {sample_model.total_params:,}\")\n",
        "print(f\"  - Dropout: 0.3\")\n",
        "\n",
        "print(f\"\\nOptimizer Configurations:\")\n",
        "for name, config in optimizer_configs.items():\n",
        "    print(f\"  - {name}: {config['params']}\")\n",
        "\n",
        "print(f\"\\nPerformance Rankings (by Best Validation Accuracy):\")\n",
        "sorted_optimizers = sorted(results.items(), key=lambda x: x[1]['best_val_acc'], reverse=True)\n",
        "for rank, (optimizer_name, data) in enumerate(sorted_optimizers, 1):\n",
        "    print(f\"  {rank}. {optimizer_name}: {data['best_val_acc']:.2f}% (Epoch {np.argmax(data['val_accs']) + 1})\")\n",
        "\n",
        "print(f\"\\nKey Observations:\")\n",
        "best_opt = sorted_optimizers[0][0]\n",
        "worst_opt = sorted_optimizers[-1][0]\n",
        "performance_gap = results[best_opt]['best_val_acc'] - results[worst_opt]['best_val_acc']\n",
        "\n",
        "print(f\"  - Best performing optimizer: {best_opt}\")\n",
        "print(f\"  - Performance gap between best and worst: {performance_gap:.2f}%\")\n",
        "print(f\"  - Most stable training: {min(results.keys(), key=lambda x: np.std(results[x]['val_accs'][-5:]))}\")\n",
        "\n",
        "# SGD specific analysis\n",
        "if 'SGD' in results:\n",
        "    sgd_data = results['SGD']\n",
        "    lr_reduction_epochs = [i for i in range(1, len(sgd_data['learning_rates'])) \n",
        "                          if sgd_data['learning_rates'][i] < sgd_data['learning_rates'][i-1]]\n",
        "    print(f\"  - SGD learning rate reductions at epochs: {[e+1 for e in lr_reduction_epochs]}\")\n",
        "\n",
        "print(f\"\\nConvergence Speed Analysis:\")\n",
        "for optimizer_name, data in results.items():\n",
        "    target_acc = 0.9 * data['best_val_acc']\n",
        "    convergence_epoch = next((i for i, acc in enumerate(data['val_accs']) if acc >= target_acc), num_epochs)\n",
        "    print(f\"  - {optimizer_name}: Reached 90% of best performance at epoch {convergence_epoch + 1}\")\n",
        "\n",
        "print(f\"\\nRecommendations:\")\n",
        "if best_opt == 'Adam':\n",
        "    print(f\"  - Adam showed best overall performance with adaptive learning rates\")\n",
        "elif best_opt == 'SGD':\n",
        "    print(f\"  - SGD with momentum and scheduling achieved best performance\")\n",
        "elif best_opt == 'RMSprop':\n",
        "    print(f\"  - RMSprop provided best adaptive optimization for this task\")\n",
        "\n",
        "print(f\"  - Consider the trade-off between convergence speed and final performance\")\n",
        "print(f\"  - Hyperparameter tuning could further improve results for each optimizer\")\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
